---
title: "Sector"
author: "Jiaxi Li"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
```

In this file, I will analysis the sector level betas and compare the REITs ones against other sectors. The data here are from Ken French Data Library 49 industry portfolios since 1993.

# Load Data

Load FF5.csv and 49_Industry_Portfolios.csv

```{r}
# load useful packages
library(tidyverse)
library(here)
library(dplyr)
```

```{r, cache = TRUE}
# load data to include only log premiums, PERMNO, and isREIT
Portfolios <- read_csv(here("data/49_Industry_Portfolios.csv"))
FF5 <- read_csv(here("data/FF5.csv"))
```

# Merge Data, Clean Data, and Regression

I will merge the data and convert the simple return to log return. Since the graph does not work well, I made it, saved it and then loaded it.

```{r, cache = TRUE}
Convert <- function(RET){return(log(RET/100+1))}

# Merge data and covert to log return
All <- Portfolios %>%
  gather(Industry, RET, - X1) %>%
  inner_join(FF5) %>%
  mutate(RP = RET - RF) %>%
  subset(select = -c(X1,RF,RET)) %>%
  mutate_if(is.numeric,Convert)

# Group the data and do the regression
Sectors <- All %>%
  group_by(Industry) %>%
  do(model = lm(RP ~ `Mkt-RF` + SMB + HML + RMW + CMA, data = .) %>%
       coefficients())

# lower bound for the confidence interval
Sectorsl <- All %>%
  group_by(Industry) %>%
  do(model = lm(RP ~ `Mkt-RF` + SMB + HML + RMW + CMA, data = .) %>%
       confint() %>%
       subset(select = "2.5 %") %>%
       t())

# upper bound for the confidence interval
Sectorsu <- All %>%
  group_by(Industry) %>%
  do(model = lm(RP ~ `Mkt-RF` + SMB + HML + RMW + CMA, data = .) %>%
       confint() %>%
       subset(select = "97.5 %") %>%
       t())

# extract the betas
Betas <- do.call(rbind.data.frame, Sectors$model) %>%
              as_tibble()

Betasl <- do.call(rbind.data.frame, Sectorsl$model) %>%
              as_tibble()

Betasu <- do.call(rbind.data.frame, Sectorsu$model) %>%
              as_tibble()

# rename the beta variables
names(Betas) = mgsub::mgsub( names(Sectors$model[[1]]), c("\\(","`","\\)"), c("","",""))
names(Betasl) = names(Betas)
names(Betasu) = names(Betas)

# join the identifiers and betas and gather coefficient
Betas1 <- (cbind(Sectors[, 1], Betas) %>%
  as_tibble() %>%
  gather(types, coefficient, -Industry)) %>%
  inner_join(
    (cbind(Sectorsl[, 1], Betasl) %>%
       as_tibble() %>%
       gather(types, coefficientl, -Industry))
  ) %>%
  inner_join(
    (cbind(Sectorsu[, 1], Betasu) %>%
       as_tibble() %>%
       gather(types, coefficientu, -Industry)))
  

# fix the order of factors
Betas1$types <- factor(Betas1$types, levels = c("Intercept","Mkt-RF","SMB","HML","RMW","CMA"))
```

```{r, eval = FALSE}
# plot the histograms
# These two functions would reorder the bars and fix the names. They are from https://github.com/dgrtwo/drlib/blob/master/R/reorder_within.R.
reorder_within <- function(x, by, within, fun = mean, sep = "___", ...) {
  new_x <- paste(x, within, sep = sep)
  stats::reorder(new_x, by, FUN = fun)
}

scale_x_reordered <- function(..., sep = "___") {
  reg <- paste0(sep, ".+$")
  ggplot2::scale_x_discrete(labels = function(x) gsub(reg, "", x), ...)
}
  
Betas1 %>%
  ggplot() +
  geom_bar(aes(reorder_within(Industry, coefficient, types),
             coefficient,
             fill = factor(
               ifelse(
                 Industry == "RlEst",
                 "Highlighted",
                 "Normal"))),
           stat = "identity",
           show.legend = FALSE) +
  geom_errorbar(
    aes(x = reorder_within(Industry, coefficient, types),
        ymin = coefficientl,
        ymax = coefficientu),
    width=0.4,
    colour="orange",
    alpha=0.9,
    size=1.3) +
  scale_fill_manual(name = "area",
                    values=c("red","grey50")) +
  labs(title= "Estimated Betas for 49 Industries",
       caption = "Source: Ken French Data Library",
       x = "Industries", y = "coefficients") +
  scale_x_reordered() +
  facet_wrap(~ types,
             ncol = 1,
             scales = "free")+
  theme(plot.title = element_text(hjust=0.5),
        axis.text.x = element_text(angle = 75, hjust = 1))

ggsave("Sectors.png", width = 3*2.5, height = 3*6, limitsize = FALSE)
```

![Here is the coefficient for different sectors](Sectors.png)


Here, I would present the risk premiums distribution for each sector.
```{r}
# density plot for the sectors
All %>%
  subset(select = c(Industry,RP)) %>%
  ggplot(aes(x = RP)) +
  geom_density() +
  facet_wrap(~Industry) +
  labs(title= "49 Industries Risk Premium Distributions",
       caption = "Source: Ken French Data Library",
       x = "Industry Risk Premium", y = "Density") +
  theme(plot.title = element_text(hjust=0.5))

# density plot for the factors
dis_factors <- All %>%
  subset(select = -c(RP, Industry)) %>%
  gather(factors, returns) %>%
  nest(returns) %>%
  mutate(y = map(data, ~ dnorm(
    .$returns, mean = mean(.$returns), sd = sd(.$returns)
    ))) %>% 
  unnest(data,y)

# fix the order of factors
dis_factors$factors <- factor(dis_factors$factors, levels = c("Mkt-RF","SMB","HML","RMW","CMA"))

# plot the factor distributions
dis_factors %>%
  ggplot(aes(x = returns)) +
  geom_density() +
  geom_line(aes(y = y, color = "normal")) +
  facet_wrap(~factors) +
  labs(title= "Fama French 5 Factors Distributions",
       caption = "Source: Ken French Data Library",
       x = "Factor Risk Premium", y = "Density") +
  theme(plot.title = element_text(hjust=0.5),
        legend.position = c(0.8, 0.2))

```

# Plot the time series plot for the betas

Using 5 year windows for a time series beta plot 
```{r, cache = TRUE}
# extract the data for the rolling window
Rolling <- All %>%
  filter(Industry == "RlEst") %>%
  cbind(FF5 %>%
          subset(select = 1)) %>%
  subset(select = -1)

# preset rolling window betas
Rolling_beta <- Rolling %>%
  filter(X1 > 199711) %>%
  rename(Intercept = RP) %>%
  subset(select = c(7,6,1:5))
  
# apply the for loop to calculate the 5-year rolling beta (60 data points)
for (i in 1:(nrow(Rolling)-59)) {
  temp <- Rolling %>%
    filter(X1<(X1[i]+500),
           X1 >= X1[i]) %>%
    do(model = lm(RP ~ `Mkt-RF` + SMB + HML + RMW + CMA, data = .) %>%
       coefficients())
  Rolling_beta[i,2:7] <- temp$model[[1]]
}

# rolling beta plots data
Rolling_Betas <- Rolling_beta %>%
  gather(types, coefficient, -X1) %>%
  mutate(X1 = paste(as.character(
    floor(X1/100)),
    "-",
    as.character(
      sprintf("%02d",
              X1-100*floor(X1/100))),
    "-01",
    sep ="")) %>%
  mutate(X1 = as.Date(X1))
  
# fix the order of factors
Rolling_Betas$types <- factor(Rolling_Betas$types, levels = c("Intercept","Mkt-RF","SMB","HML","RMW","CMA"))

# plot the time-series betas
Rolling_Betas %>%
  ggplot() +
  geom_line(aes(X1,
             coefficient)) +
  scale_x_date() +
  labs(title= "Estimated 5-year Betas for REITs",
       caption = "Source: Ken French Data Library",
       x = "date", y = "coefficients") +
  facet_wrap(~ types,
             scales = "free")+
  theme(plot.title = element_text(hjust=0.5),
        axis.text.x = element_text(angle = 75, hjust = 1))

```

# Full Sample Second-Pass Fama Macbeth

```{r, cache = TRUE}
# here, I will just use the previously estimated Betas1 and come up with Betas2 for the second stage regression
All2 <- Portfolios %>%
  gather(Industry, RET, - X1) %>%
  inner_join(FF5) %>%
  mutate(RP = RET - RF) %>%
  subset(select = - c(RF, RET)) %>%
  mutate_if(is.numeric,Convert) %>%
  mutate(X1 = (exp(X1)-1)*100)

# extract the betas I need from previous estimation
Betas2 <- cbind(Sectors[, 1], Betas) %>%
  as_tibble() %>%
  inner_join(All2 %>%
               subset(select = c(X1, Industry, RP)) %>%
               rename(date = X1) %>%
               subset(date < 201911)) %>%
  subset(select = -Intercept)

# Group the data and do the second pass regression
Second <- Betas2 %>%
  group_by(date) %>%
  do(model = lm(RP ~ `Mkt-RF` + SMB + HML + RMW + CMA, data = .) %>%
       coefficients())

# Calculate the cook's distance for each period
Second_cook <- Betas2 %>%
  group_by(date) %>%
  do(model = lm(RP ~ `Mkt-RF` + SMB + HML + RMW + CMA, data = .) %>%
       cooks.distance())

# Unwrap the results
Lambdas <- do.call(rbind.data.frame, Second$model) %>%
              as_tibble()
Lambdas_cook <- do.call(rbind.data.frame, Second_cook$model) %>%
              as_tibble()

# Rename the variables
names(Lambdas) = mgsub::mgsub(names(Second$model[[1]]), c("\\(","`","\\)"), c("","",""))
names(Lambdas_cook) = names(Portfolios %>% subset(select = -X1))

# Add in the dates
Lambdas <- cbind(Second[, 1], Lambdas) %>%
  gather(Factors, RP, - date)
Lambdas_cook <- cbind(Second_cook[, 1], Lambdas_cook) %>%
  gather(Industry, CD, - date)

# fix the order of factors
Lambdas$Factors <- factor(Lambdas$Factors, levels = c("Intercept","Mkt-RF","SMB","HML","RMW","CMA"))

# Create the data for the plot of the lambdas and cook's distance
Lambdas1 <- Lambdas %>%
  group_by(Factors) %>%
  summarise(RPm = mean(RP),
            RPl = RPm - qnorm(.975)*(sd(RP)/sqrt(322)),
            RPu = RPm + qnorm(.975)*(sd(RP)/sqrt(322)))

Lambdas_cook1 <- Lambdas_cook %>%
  group_by(Industry) %>%
  summarise(CDm = mean(CD),
            CDl = CDm - qnorm(.975)*(sd(CD)/sqrt(322)),
            CDu = CDm + qnorm(.975)*(sd(CD)/sqrt(322)))

# Plot the Lambda estimations of the second pass regression
Lambdas1 %>%
  ggplot() +
  geom_bar(aes(Factors,
             RPm),
           stat = "identity",
           show.legend = FALSE) +
  geom_errorbar(
    aes(x = Factors,
        ymin = RPl,
        ymax = RPu),
    width=0.4,
    colour="orange",
    alpha=0.9,
    size=1.3) +
  labs(title= "Estimated Risk Premiums for Fama French 5 Factors with 49 Industry Portfolios",
       caption = "Source: Ken French Data Library",
       x = "Factors", y = "Factor Premiums") +
  theme(plot.title = element_text(hjust=0.5),
        axis.text.x = element_text(angle = 75, hjust = 1))

# Plot the Cook's distance for each sector
Lambdas_cook1 %>%
  ggplot() +
  geom_bar(aes(Industry,
             CDm,
             fill = factor(
               ifelse(
                 Industry == "RlEst",
                 "Highlighted",
                 "Normal"))),
           stat = "identity",
           show.legend = FALSE) +
  geom_errorbar(
    aes(x = Industry,
        ymin = CDl,
        ymax = CDu),
    width=0.4,
    colour="orange",
    alpha=0.9,
    size=1.3) +
  geom_hline(yintercept = 4/49,
             linetype="dashed",
             color = "green",
             size = 2) +
  scale_fill_manual(name = "area",
                    values=c("red","grey50")) +
  labs(title= "Cook's Distance for the Regressions",
       caption = "Source: Ken French Data Library",
       x = "Industries", y = "Cooks' Distance") +
  theme(plot.title = element_text(hjust=0.5),
        axis.text.x = element_text(angle = 75, hjust = 1))
```

With the Cook's Distance estimation, REITs does not seem to pull the factor premium estimation of the second pass Fama Macbeth.

# Rolling-Window Second-Pass Fama Macbeth

Here, I would apply the 5-year rolling window to estimate the betas and use them to calculate the lambdas for the following month.

```{r, cache = TRUE}
# preset rolling window betas
Rolling_beta1 <- All2 %>%
  filter(X1 > 199711) %>%
  rename(Intercept = RP) %>%
  subset(select = c(1,2,8,3:7)) %>%
  group_by(Industry)

# calculate the betas using a for loop, I will use the "Sectors" for Industry names
for (j in 1:49) {
  Rolling1 <- All2 %>%
    filter(Industry == toString(Sectors[j,1]))
  
  # apply the for loop to calculate the 5-year rolling beta (60 data points)
  for (k in 1:(nrow(Rolling1)-59)) {
    temp <- Rolling1 %>%
      filter(X1<(X1[k]+500),
             X1 >= X1[k]) %>%
      do(model = lm(RP ~ `Mkt-RF` + SMB + HML + RMW + CMA, data = .) %>%
         coefficients())
    Rolling_beta1[(j-1)*nrow(Rolling_beta1)/49+k,3:8] <- temp$model[[1]]
  }
}

# set the dataset for second pass regression
Rolling_beta2 <- Rolling_beta1 %>%
  inner_join(All2 %>%
               ungroup() %>%
               subset(select = c(X1, Industry, RP))) %>%
  subset(select = -Intercept) %>%
  rename(date = X1) %>%
  ungroup()

# Group the data and do the second pass regression
Rolling_Second <- Rolling_beta2 %>%
  group_by(date) %>%
  do(model = lm(RP ~ `Mkt-RF` + SMB + HML + RMW + CMA, data = .) %>%
       coefficients())

# Calculate the cook's distance for each period
Rolling_Second_cook <- Rolling_beta2 %>%
  group_by(date) %>%
  do(model = lm(RP ~ `Mkt-RF` + SMB + HML + RMW + CMA, data = .) %>%
       cooks.distance())

# Unwrap the results
Rolling_Lambdas <- do.call(rbind.data.frame, Rolling_Second$model) %>%
              as_tibble()
Rolling_Lambdas_cook <- do.call(rbind.data.frame, Rolling_Second_cook$model) %>%
              as_tibble()

# Rename the variables
names(Rolling_Lambdas) = mgsub::mgsub(names(Rolling_Second$model[[1]]), c("\\(","`","\\)"), c("","",""))
names(Rolling_Lambdas_cook) = names(Portfolios %>% subset(select = -X1))

# Add in the dates
Rolling_Lambdas <- cbind(Rolling_Second[, 1], Rolling_Lambdas) %>%
  gather(Factors, RP, - date)
Rolling_Lambdas_cook <- cbind(Rolling_Second_cook[, 1], Rolling_Lambdas_cook) %>%
  gather(Industry, CD, - date)

# fix the order of factors
Rolling_Lambdas$Factors <- factor(Rolling_Lambdas$Factors, levels = c("Intercept","Mkt-RF","SMB","HML","RMW","CMA"))

# Create the data for the plot of the lambdas and cook's distance
Rolling_Lambdas1 <- Rolling_Lambdas %>%
  group_by(Factors) %>%
  summarise(RPm = mean(RP),
            RPl = RPm - qnorm(.975)*(sd(RP)/sqrt(262)),
            RPu = RPm + qnorm(.975)*(sd(RP)/sqrt(262)))

Rolling_Lambdas_cook1 <- Rolling_Lambdas_cook %>%
  group_by(Industry) %>%
  summarise(CDm = mean(CD),
            CDl = CDm - qnorm(.975)*(sd(CD)/sqrt(262)),
            CDu = CDm + qnorm(.975)*(sd(CD)/sqrt(262)))

# Plot the Lambda estimations of the second pass regression
Rolling_Lambdas1 %>%
  ggplot() +
  geom_bar(aes(Factors,
             RPm),
           stat = "identity",
           show.legend = FALSE) +
  geom_errorbar(
    aes(x = Factors,
        ymin = RPl,
        ymax = RPu),
    width=0.4,
    colour="orange",
    alpha=0.9,
    size=1.3) +
  labs(title= "Rolling Window Estimated Risk Premiums for Fama French 5 Factors with 49 Industry Portfolios",
       caption = "Source: Ken French Data Library",
       x = "Factors", y = "Factor Premiums") +
  theme(plot.title = element_text(hjust=0.5),
        axis.text.x = element_text(angle = 75, hjust = 1))

# Plot the Cook's distance for each sector
Rolling_Lambdas_cook1 %>%
  ggplot() +
  geom_bar(aes(Industry,
             CDm,
             fill = factor(
               ifelse(
                 Industry == "RlEst",
                 "Highlighted",
                 "Normal"))),
           stat = "identity",
           show.legend = FALSE) +
  geom_errorbar(
    aes(x = Industry,
        ymin = CDl,
        ymax = CDu),
    width=0.4,
    colour="orange",
    alpha=0.9,
    size=1.3) +
  geom_hline(yintercept = 4/49,
             linetype="dashed",
             color = "green",
             size = 2) +
  scale_fill_manual(name = "area",
                    values=c("red","grey50")) +
  labs(title= "Cook's Distance for the Rolling Window Regressions",
       caption = "Source: Ken French Data Library",
       x = "Industries", y = "Cooks' Distance") +
  theme(plot.title = element_text(hjust=0.5),
        axis.text.x = element_text(angle = 75, hjust = 1))

```

Even with Rolling Windows, the Cook's Distance estimation shows that REITs does not seem to pull the factor premium estimation of the second pass Fama Macbeth.

# Save the rolling-window lambda estimations
```{r, eval=FALSE}
Rolling_Lambdas %>%
  mutate(date = round(date))

Rolling_Lambdas %>%
  write_csv(here("data","Rolling_Lambdas.csv"))
```

